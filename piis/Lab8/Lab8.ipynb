{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №8 Генерация текста на основе “Алисы в стране чудес”\n",
    "### Выполнила студентка группы БВТ2101 Пьянова Анна Олеговна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель работы\n",
    "Рекуррентные нейронные сети также могут быть использованы в качестве генеративных\n",
    "моделей.\n",
    "Это означает, что в дополнение к тому, что они используются для прогнозных моделей\n",
    "(создания прогнозов), они могут изучать последовательности проблемы, а затем\n",
    "генерировать совершенно новые вероятные последовательности для проблемной\n",
    "области.\n",
    "Подобные генеративные модели полезны не только для изучения того, насколько хорошо\n",
    "модель выявила проблему, но и для того, чтобы узнать больше о самой проблемной\n",
    "области.\n",
    "\n",
    "### Задачи:\n",
    "- Ознакомиться с генерацией текста\n",
    "- Ознакомиться с системой Callback в Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполнение работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input\n",
    "from keras.callbacks import ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка текста книги, подготовка данных для моделирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144679\n",
      "Total Vocab:  51\n"
     ]
    }
   ],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read().lower()\n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертация символов в целые числа с помощью ранее подготовленной таблицы поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144579\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование списка входных последовательностей для использования с Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение LSTM модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X.shape[1], X.shape[2])))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 3.0965\n",
      "Epoch 1: loss improved from inf to 3.01685, saving model to weights-improvement-01-3.0168.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 233ms/step - loss: 3.0964\n",
      "Epoch 2/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 2.8506\n",
      "Epoch 2: loss improved from 3.01685 to 2.81757, saving model to weights-improvement-02-2.8176.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 245ms/step - loss: 2.8506\n",
      "Epoch 3/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 2.7241\n",
      "Epoch 3: loss improved from 2.81757 to 2.70970, saving model to weights-improvement-03-2.7097.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 216ms/step - loss: 2.7240\n",
      "Epoch 4/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 2.6532\n",
      "Epoch 4: loss improved from 2.70970 to 2.63916, saving model to weights-improvement-04-2.6392.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 204ms/step - loss: 2.6532\n",
      "Epoch 5/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 2.5838\n",
      "Epoch 5: loss improved from 2.63916 to 2.57527, saving model to weights-improvement-05-2.5753.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 202ms/step - loss: 2.5838\n",
      "Epoch 6/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 2.5297\n",
      "Epoch 6: loss improved from 2.57527 to 2.51715, saving model to weights-improvement-06-2.5171.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 202ms/step - loss: 2.5296\n",
      "Epoch 7/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 2.4766\n",
      "Epoch 7: loss improved from 2.51715 to 2.46873, saving model to weights-improvement-07-2.4687.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 206ms/step - loss: 2.4766\n",
      "Epoch 8/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 2.4226\n",
      "Epoch 8: loss improved from 2.46873 to 2.41961, saving model to weights-improvement-08-2.4196.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 206ms/step - loss: 2.4226\n",
      "Epoch 9/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 2.3773\n",
      "Epoch 9: loss improved from 2.41961 to 2.37558, saving model to weights-improvement-09-2.3756.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 241ms/step - loss: 2.3773\n",
      "Epoch 10/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 2.3360\n",
      "Epoch 10: loss improved from 2.37558 to 2.33588, saving model to weights-improvement-10-2.3359.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 246ms/step - loss: 2.3360\n",
      "Epoch 11/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 2.2953\n",
      "Epoch 11: loss improved from 2.33588 to 2.29579, saving model to weights-improvement-11-2.2958.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 250ms/step - loss: 2.2953\n",
      "Epoch 12/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 2.2574\n",
      "Epoch 12: loss improved from 2.29579 to 2.26009, saving model to weights-improvement-12-2.2601.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 251ms/step - loss: 2.2574\n",
      "Epoch 13/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 2.2201\n",
      "Epoch 13: loss improved from 2.26009 to 2.22325, saving model to weights-improvement-13-2.2233.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 249ms/step - loss: 2.2201\n",
      "Epoch 14/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 2.1831\n",
      "Epoch 14: loss improved from 2.22325 to 2.18703, saving model to weights-improvement-14-2.1870.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 248ms/step - loss: 2.1831\n",
      "Epoch 15/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 2.1450\n",
      "Epoch 15: loss improved from 2.18703 to 2.15304, saving model to weights-improvement-15-2.1530.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 261ms/step - loss: 2.1450\n",
      "Epoch 16/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 2.1132\n",
      "Epoch 16: loss improved from 2.15304 to 2.12081, saving model to weights-improvement-16-2.1208.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 211ms/step - loss: 2.1132\n",
      "Epoch 17/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 2.0905\n",
      "Epoch 17: loss improved from 2.12081 to 2.09137, saving model to weights-improvement-17-2.0914.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 188ms/step - loss: 2.0905\n",
      "Epoch 18/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2.0453\n",
      "Epoch 18: loss improved from 2.09137 to 2.06005, saving model to weights-improvement-18-2.0601.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 193ms/step - loss: 2.0453\n",
      "Epoch 19/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2.0266\n",
      "Epoch 19: loss improved from 2.06005 to 2.03262, saving model to weights-improvement-19-2.0326.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 185ms/step - loss: 2.0266\n",
      "Epoch 20/20\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2.0042\n",
      "Epoch 20: loss improved from 2.03262 to 2.00762, saving model to weights-improvement-20-2.0076.keras\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 183ms/step - loss: 2.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d37ddcc650>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация текста с помощью сети LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X.shape[1], X.shape[2])))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# load the network weights\n",
    "filename = \"weights-improvement-20-2.0076.keras\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ourt_.”\n",
      "\n",
      "everybody looked at alice.\n",
      "\n",
      "“_i’m_ not a mile high,” said alice.\n",
      "\n",
      "“you are,” said the king. \"\n",
      " “ih io would toe koot be anoine to the toons!”\n",
      "\n",
      "“h whou d shrl mo his to ”hur mote ” thiught alice, “ih wou’te you dno the horse to the karee hare ” \n",
      "“h den’t teon toe thing?” she mock turtle seilied \n",
      "the wai io a ger lece to the tab it an an anoed toe tai  “ho  yhu  i wouldn the korse woule ”ou goow the dormo, io a lorg aro oi the sooe.”\n",
      "\n",
      "“i whilk y said the mock turtle, “ih io wish the woudd ae a loeg tu the thate  and i sas an toed an io ”h\n",
      "the koot an a lors ”ou shonkn the mooer.” \n",
      "“i whin you  a  oh _ourse,” thiught alice, “in wou dn wou toonte toe thin ho ”h\n",
      "thenk io would be a loog aro oi atery_nnn, and it would be a loog tiie  she wisle bate wai iott an an anl of the sabbit, and the woide to the gurhous woice  the was tointing at the could  the was tointing an the courd  ao ae ano whthe to thyh the soee  the was to toint toen a cond oide toee and the card so tee thet had so the taa it an in whit had  and the while rabbit war anine to the toed   fh pai io a lorr wish arohous to\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:]\n",
    "    \n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация собственного CallBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.9741\n",
      "Epoch 1 - Generated Text:\n",
      "Seed:\n",
      "\" lice, she went on, “what’s your name, child?”\n",
      "\n",
      "“my name is alice, so please your majesty,” said alic \"\n",
      "e in a soneoo tonc. \n",
      "“ih coorse toeh io ”hur a tey oo tie,” said the guyphon, “io would toe kocw tha\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 191ms/step - loss: 1.9741\n",
      "Epoch 2/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.9440\n",
      "Epoch 2 - Generated Text:\n",
      "Seed:\n",
      "\" e i’m not ada,” she said, “for her hair goes in such long\n",
      "ringlets, and mine doesn’t go in ringlets  \"\n",
      "an anl  a donro taa int tee sooe of the sab it an in was toier in the ras. \n",
      "“h woolt toen to ae anda\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 163ms/step - loss: 1.9440\n",
      "Epoch 3/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.9228\n",
      "Epoch 3 - Generated Text:\n",
      "Seed:\n",
      "\" . (it was\n",
      "this last remark that had made the whole party look so grave and\n",
      "anxious.)\n",
      "\n",
      "alice could th \"\n",
      "e katter was a little broree  she cade to tie taatid anl har fare wo tee thet sae an in had so the t\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 162ms/step - loss: 1.9229\n",
      "Epoch 4/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.9019\n",
      "Epoch 4 - Generated Text:\n",
      "Seed:\n",
      "\" d\n",
      "nothing, being fast asleep.\n",
      "\n",
      "“after that,” continued the hatter, “i cut some more bread-and-butter \"\n",
      " wou to lete tou doen hn the was oh the sooe.”\n",
      "\n",
      "“i won’td dad to tere the rimt oi the soms,” she man\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 160ms/step - loss: 1.9020\n",
      "Epoch 5/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.8844\n",
      "Epoch 5 - Generated Text:\n",
      "Seed:\n",
      "\"  must have a trial: for really this morning i’ve\n",
      "         nothing to do.’ said the mouse to the cur, \"\n",
      "of the telee hfreer, \n",
      "“io yould bo ho moteed the samt whing ” said alice, “i’’ al anliotsen  the mag\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 161ms/step - loss: 1.8844\n",
      "Epoch 6/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.8616\n",
      "Epoch 6 - Generated Text:\n",
      "Seed:\n",
      "\" ap of her sister, who was gently brushing away some dead\n",
      "leaves that had fluttered down from the tre \"\n",
      "e a bet rf the tabbit was soen it wo tee the rame of the was soine to tee thet saaein, and taed to h\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 159ms/step - loss: 1.8616\n",
      "Epoch 7/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.8489\n",
      "Epoch 7 - Generated Text:\n",
      "Seed:\n",
      "\" ter\n",
      "worse. you _must_ have meant some mischief, or else you’d have signed\n",
      "your name like an honest m \"\n",
      "ine toen i teon k an anl ano toet,”\n",
      "\n",
      "“i dan’t knlw it i saa ”ou fave to the gare ”ou gane ii the can\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 160ms/step - loss: 1.8490\n",
      "Epoch 8/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.8322\n",
      "Epoch 8 - Generated Text:\n",
      "Seed:\n",
      "\" h a fall as this, i shall\n",
      "think nothing of tumbling down stairs! how brave they’ll all think me\n",
      "at h \"\n",
      "ers an ifrt ane anoee and suedren. \n",
      "“h don’t know the maat tf the said that s aaie w the maccht seit\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 160ms/step - loss: 1.8322\n",
      "Epoch 9/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.8045\n",
      "Epoch 9 - Generated Text:\n",
      "Seed:\n",
      "\"  the\n",
      "court!” and the king put on his spectacles and looked anxiously round,\n",
      "to make out who was talk \"\n",
      "ing  bnd tareng on the tooe  the was notiigg at the could set ano siree hnr \n",
      " “he you don’t know the\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 158ms/step - loss: 1.8045\n",
      "Epoch 10/10\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.7998\n",
      "Epoch 10 - Generated Text:\n",
      "Seed:\n",
      "\"  upon her arm, and timidly said “consider, my\n",
      "dear: she is only a child!”\n",
      "\n",
      "the queen turned angrily  \"\n",
      "and eoowted herself, and she wasted to sae it a lote tile wh cerlere the sabbit woree the was no thr\n",
      "\n",
      "\u001b[1m1130/1130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 158ms/step - loss: 1.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1473f4e32d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextGenerationCallback(Callback):\n",
    "    def __init__(self, dataX, int_to_char, n_vocab, seq_length):\n",
    "        super(TextGenerationCallback, self).__init__()\n",
    "        self.dataX = dataX\n",
    "        self.int_to_char = int_to_char\n",
    "        self.n_vocab = n_vocab\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        start = np.random.randint(0, len(self.dataX) - 1)\n",
    "        pattern = self.dataX[start]\n",
    "        print(f\"\\nEpoch {epoch + 1} - Generated Text:\")\n",
    "        print(\"Seed:\")\n",
    "        print(\"\\\"\", ''.join([self.int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "        # generate characters\n",
    "        for i in range(100):\n",
    "            x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "            x = x / float(self.n_vocab)\n",
    "            prediction = self.model.predict(x, verbose=0)\n",
    "            index = np.argmax(prediction)\n",
    "            result = self.int_to_char[index]\n",
    "            seq_in = [self.int_to_char[value] for value in pattern]\n",
    "            sys.stdout.write(result)\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:len(pattern)]\n",
    "        print(\"\\n\")\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "text_gen_callback = TextGenerationCallback(dataX, int_to_char, n_vocab, seq_length)\n",
    "\n",
    "model.fit(X, y, epochs=10, batch_size=128, callbacks=[text_gen_callback, tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  she had\n",
      "drunk half the bottle, she found her head pressing against the ceiling,\n",
      "and had to stoop to \"\n",
      " toen the roee afner her ane ano ofc thet, and she was soeiting at the could sed whn, and tee whnt on anoneed anonh the carese and she whnee har hne the ragl of the saali. \n",
      "“he you don’t know what _ yhre then you toon lo ”our majesty,” said the mrek turtle. \n",
      "“ie course wour have ”our majesty,” said the manch hare.\n",
      "\n",
      "“ie course oo hes seme” an i meoe,” said the dat, “io you dne’ wesh the dorttr of the bance.\n",
      "int ier weil then!”\n",
      "\n",
      "“ho  yher _s _ lore waye” said theee ”hur mace ”ou sorl oo here to toaa and oucered th the white ” she said to herself, “it would be anhan  a dondo tfll the wond,”\n",
      "\n",
      "“h whsh y said the mucen so the cormerse in the wan oo ano oiretee. \n",
      "“ie you doe’ was in anl the seal” ”hat i toudd woul here a gen in ”hs aaner? ii a large fande?” \n",
      "“i whal the was no ” said the mock turtle. \n",
      "“ie course wour have ”our majesty,” said the manch hare.\n",
      "\n",
      "“ie course mo tee,” said the moek turtle. \n",
      "“ie course wour have ”our majesty,” said the manch hare.\n",
      "\n",
      "“ie course mo tee,” said the moek t\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "filename = \"model.keras\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:]\n",
    "    \n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отслеживание процесса обучения с помощью TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 15056), started 11:32:00 ago. (Use '!kill 15056' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-541f167b768230c8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-541f167b768230c8\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.weights.h5')\n",
    "model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
